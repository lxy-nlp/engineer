DSSM

摘要:

应用场景: 大规模Web搜索应用

做法:将查询和文本映射到一个普通的低维空间.提出的深层结构语义模型有区别地通过最大化点击文本的条件概率.



引言:

现代搜索引擎的搜索原理: 通过查询 匹配 文本中的关键词.

传统的方法 LSA 将 查询和相关文本形成一个映射.缺点 语义匹配能力不足. 这些隐语义模型解决了搜索建和文档之间的语言差异 通过将出现在类似上下文中的不同术语分组到相同的语义集群。因此一个查询和一个文档,在语义空间中代表两个向量,仍然可以有很高的相似度分数尽管他们没有相同的单词.作为LSA的扩展,PLSA LDA 用于语义匹配. 然而这些模型的效果并没有想象中的好.

现有的两种研究方向:

1. 减少查询 和 网页文本的差异

2. 通过深度学习抽取特征

   

   本文的方法 

![image-20210419142049548](/home/lxy/文档/学习笔记/img/image-20210419142049548.png)

创新点 word hashing

词袋模型

```shell
构造字典 
统计字/词出现的次数 
缺点 忽略词序 维度可能爆炸
```

针对 维度问题使用word hashing降维

500k的字典可以降到 30k 利用 letter-trigram, 仅仅会有0.0044%的碰撞

![image-20210419144138485](/home/lxy/文档/学习笔记/img/image-20210419144138485.png)

后续的改进

主要是在编码器上变更  使用CNN LSTM 等等作为编码器,原文中主要是多层感知机

词向量的构造 改进 不适用letter级别的trigram 而是使用预训练的词向量.



拓展

双塔模型在推荐系统中的应用

两个塔代表的 与上述 文本匹配的异同:

query是用户的行为和信息,candidate是要推荐的商品

另外 商品数据量庞大,不可能一次性计算出所有的候选商品

因此使用在一个minibatch中使用负采样的方法 减少计算量

什么是负采样



孪生神经网络

类似与DSSM 准备看完后补充





搜狐比赛

思路:

短文本 TextCNN

长文本 HAN

通吃 BiLSTM + Attention

终极 BERT + FineTune