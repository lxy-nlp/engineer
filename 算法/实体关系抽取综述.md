## 基本概念

### TP TN FP FN概念

|                             | 相关（Relevant），正类                                       | 无关（NonRelevant），负类                                    |
| :-------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 被检索到（Retrieved）       | True Positives（TP，正类判定为正类。即女生是女生）           | False Positives（FP，负类判定为正类，即“存伪”。男生判定为女生） |
| 未被检索到（Not Retrieved） | False Negatives（FN，正类判定为负类，即“去真”。女生判定为男生） | True Negatives（TN，负类判定为负类。即男生判定为男生）       |

### 准确率 精确率 召回率 F1

准确率
$$
Accuracy =TP + TN/TP+TN+FP+FN
$$
精确率
$$
Precision=TP/TP+FP
$$
召回率
$$
Recall = TP/TP+FN
$$
F1值
$$
F1=1/Precision + 1/Recall
$$

## 实体关系抽取

### 管道式抽取

​	管道式抽取是将实体关系抽取看成是两个子任务,首先进行关系抽取,再进行关系抽取

#### 实体抽取

​	实体抽取(命名实体识别),有多种标注策略,如BIO BIOES等,将单词对应的实体类型 所在实体的位置都标注出来.实体类型包括 人名 地名 组织名 其他等,单词所在的实体位置有begin inner end等.

#### 关系抽取

关系抽取是在已知句子中两个实体的情况下,对实体之间存在的关系进行分类,本质上是多分类任务

主流方法:

基于RNN

​	Yan 等人[11]在 2015 年提出了基于 LSTM 的融合句法依存分析树的最短路径以及词向量特征、词性特征、WordNet 特征、句法类型特征来进行关系抽取.Thien 等人[22]基于已有工作经验,利用传统特征工程并结合 CNN,RNN 网络的优势,在 2015 年提出一种融合传统特征工程和神经网络的方法,首次系统地检测了 RNN 架构以及 RNN 与 CNN 和传统的基于特征的关系抽取方法相结合的工作.为避免 Yan 等人提出的模型需要从 NLP 预处理工具中提取附加特征带来的错误传播问题,Li 等人[50]于2016年提出一种基于低成本序列特征的 Bi-LSTM-RNN模型,利用实体对并将它们周围的上下文分段表示来获取更丰富的语义信息,无需词性标注、依存句法树等额外特征.

基于CNN

​	Zeng 等人[20]在 2014 年首次提出了使用 CNN 进行关系抽取,利用卷积深度神经网络(CDNN)来提取词汇和句子层次的特征,将所有的单词标记作为输入,而无需复杂的预处理,解决了从预处理系统中提取的特征可能会导致错误传播并阻碍系统性能的问题. Xu 等人[47]于 2015 年在 Zeng 等人工作的基础上提出了基于依存分析树的卷积神经网络的实体关系抽取模型,该模型与 Zeng 等人的 CNN 模型不同的是将输入文本经过了依存分析树,同时提出了一种负采样策略: Santos 等人[21]在 2015 年提出了 CR-CNN 模型,与 Zeng 等人的模型相比,CR-CNN 将最后的 Softmax 输出层替换为利用排名进行分类输出:对于给定的输入文本段,网络使用卷积层产生文本的分布向量表示,并将其与文本示进行比较,以便为每个类生成分数;同时提出了一种新的排名损失函数,能够给予正确的预测类更高的评分、错误的预测类更低的评分

基于GCN

​	提出GP_GCN,通过LSTM对句子进行编码,编码的结果作为图神经网络中边的权重,通过图神经网络对句子进行编码后实现关系分类;在进行关系分类的过程中,穷举句子中所有实体的组合,分别判断其关系.

--使用句法依存树构造图,并提出一种硬剪枝的策略,使用argmax的近似函数用于选择是否保留该条边;**提出AGGCN与--不同的是利用自注意力机制求得边的权重,最后进行关系分类,注意力的权重在此起到了一种弱剪枝的作用.

### 联合抽取

​	联合抽取是将实体关系抽取作为一个整体任务,同时进行实体抽取和关系抽取.

#### 参数共享

​	针对流水线方法中存在的错误累积传播问题和忽视两个子任务间关系依赖的问题,基于参数共享的实体
关系抽取方法被提出.在此方法中,实体识别子任务和关系抽取子任务通过共享联合模型的编码层来进行联合
学习,通过共享编码层,在训练时,两个子任务都会通过后向传播算法更新编码层的共享参数,以此来实现两个
子任务之间的相互依赖,最终找到全局任务的最佳参数,实现性能更佳的实体关系抽取系统.在联合学习模型
中,输入的句子在通过共享的编码层后,在解码层会首先进行实体识别子任务,再利用实体识别的结果,并对存
在关系的实体对进行关系分类,最终输出实体-关系三元组

#### 序列标注

​	序列标注策略是对关系三元组中的头实体/尾实体/关系进行位置的标注.基于参数共享的实体关系抽取方法,改善了传统流水线方法中存在的错误累积传播问题和忽视两个子任务间关系依赖的问题.但因其在训练时还是需要先进行命名实体识别子任务,再根据实体预测信息对实体进行两两匹配,最后进行关系分类子任务,因其在模型实现过程中分开完成了命名实体识别和关系分类这两个子任务,仍然会产生没有关系实体这种冗余信息.为了解决这个问题,基于新序列标注方法的实体、关系联合抽取方法被提出

​	Zheng 等人[55]在 2017 年提出了基于新的标注策略的实体关系抽取方法,把原来涉及到命名实体识别和关系分类两个子任务的联合学模型完全变成了一个序列标注问题.在该方法中,共包含 3 种标注信息:
(1) 实体中词的位置信息{B,I,E,S,O},分别表示{实体开始,实体内部,实体结束,单个实体,无关词};

(2) 实体关系类型信息,需根据实际需要自定义关系类型并编码,如{CF,CP,…};

(3) 实体角色信息{1,2},分别表示{实体 1,实体 2}.

该方法能使用序列标注的方法同时识别出实体和关系,避免了复杂的特征工程,通过一个端到端的神经网络模型直接得到实体-关系三元组,解决了基于参数共享的实体关系抽取方法可能会带来的实体冗余的问题.

--提出一种新的标注策略,和先前的通过两实体去寻找关系的方法不同,作者利用主体和关系寻找客体,一定程度上缓解了关系三元组中的实体重叠问题.



关系抽取中的常用算法模型

1. seq2seq

   定义:

   在⾃然语⾔处理的很多应⽤中，输⼊和输出都可以是不定⻓序列。以机器翻译为例，输⼊可以是⼀段不定⻓的英语⽂本序列，输出可以是⼀段不定⻓的法语⽂本序列，例如：

   英语输⼊：“They”、“are”、“watching”、“.”

   法语输出：“Ils”、“regardent”、“.”

   当输⼊和输出都是不定⻓序列时，我们可以使⽤编码器—解码器（encoder-decoder）或者seq2seq模型。**序列到序列模型，简称seq2seq模型。这两个模型本质上都⽤到了两个循环神经⽹络，分别叫做编码器和解码器。编码器⽤来分析输⼊序列，解码器⽤来⽣成输出序列

   编码器的作⽤是把⼀个不定⻓的输⼊序列变换成⼀个定⻓的背景变量 c，并在该背景变量中编码输⼊序列信息。常⽤的编码器是循环神经⽹络。

   让我们考虑批量⼤小为1的时序数据样本。假设输⼊序列是 x1, . . . , xT，例如 xi 是输⼊句⼦中的第 i 个词。在时间步 t，循环神经⽹络将输⼊ xt 的特征向量 xt 和上个时间步的隐藏状态ht−1ht−1变换为当前时间步的隐藏状态ht。我们可以⽤函数 f 表达循环神经⽹络隐藏层的变换：

   ht=f(xt,ht−1)ht=f(xt,ht−1)

   

   接下来，编码器通过⾃定义函数 q 将各个时间步的隐藏状态变换为背景变量：

   

   

   c=q(h1,...,hT)c=q(h1,...,hT)

   

   例如，当选择 *q*(***h***1*, . . . ,* ***h****T* ) = ***h****T* 时，背景变量是输⼊序列最终时间步的隐藏状态***h****T*。

   以上描述的编码器是⼀个单向的循环神经⽹络，每个时间步的隐藏状态只取决于该时间步及之前的输⼊⼦序列。我们也可以使⽤双向循环神经⽹络构造编码器。在这种情况下，编码器每个时间步的隐藏状态同时取决于该时间步之前和之后的⼦序列（包括当前时间步的输⼊），并编码了整个序列的信息。

2. attention机制

3. Transformers





